{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_id</th>\n",
       "      <th>distance</th>\n",
       "      <th>avgDelay</th>\n",
       "      <th>avgFare</th>\n",
       "      <th>airline_id_hotkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1018941</th>\n",
       "      <td>UA</td>\n",
       "      <td>550.0</td>\n",
       "      <td>4.25</td>\n",
       "      <td>128.119181</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018942</th>\n",
       "      <td>UA</td>\n",
       "      <td>2288.0</td>\n",
       "      <td>37.75</td>\n",
       "      <td>544.455055</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018943</th>\n",
       "      <td>UA</td>\n",
       "      <td>909.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>211.690722</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018944</th>\n",
       "      <td>UA</td>\n",
       "      <td>1222.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>309.176361</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018945</th>\n",
       "      <td>UA</td>\n",
       "      <td>191.0</td>\n",
       "      <td>57.75</td>\n",
       "      <td>41.295721</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        airline_id  distance  avgDelay     avgFare  airline_id_hotkey\n",
       "1018941         UA     550.0      4.25  128.119181                  9\n",
       "1018942         UA    2288.0     37.75  544.455055                  9\n",
       "1018943         UA     909.0      7.50  211.690722                  9\n",
       "1018944         UA    1222.0     26.00  309.176361                  9\n",
       "1018945         UA     191.0     57.75   41.295721                  9"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_processed = pd.read_csv(\"processed_traffic.csv\")\n",
    "\n",
    "traffic_processed.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traffic_processed[['avgFare', 'distance']]\n",
    "y = traffic_processed['avgDelay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the XGBoost regression model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 19.352822423891546\n"
     ]
    }
   ],
   "source": [
    "# Calculate the root mean squared error (RMSE) as the evaluation metric\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avgFare  distance  avgDelay  airline_id_hotkey\n",
      "0        0.353063  0.351777  0.014625           0.000000\n",
      "1        0.353063  0.351777  0.010969           0.000000\n",
      "2        0.121350  0.121365  0.015996           0.000000\n",
      "3        0.121572  0.114903  0.008684           0.000000\n",
      "4        0.312157  0.314216  0.069470           0.000000\n",
      "...           ...       ...       ...                ...\n",
      "1018941  0.104568  0.104806  0.007313           0.727273\n",
      "1018942  0.444370  0.455775  0.068556           0.727273\n",
      "1018943  0.172777  0.177302  0.013254           0.727273\n",
      "1018944  0.252342  0.240509  0.047075           0.727273\n",
      "1018945  0.033705  0.032310  0.105119           0.727273\n",
      "\n",
      "[1018946 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Select the numeric columns that you want to normalize\n",
    "numeric_columns = ['avgFare', 'distance', 'avgDelay', 'airline_id_hotkey']\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Fit and transform the selected numeric columns\n",
    "test[numeric_columns] = scaler.fit_transform(traffic_processed[numeric_columns])\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test[['avgFare', 'distance']]\n",
    "y = test['avgDelay']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost regression model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgFare</th>\n",
       "      <th>distance</th>\n",
       "      <th>avgDelay</th>\n",
       "      <th>airline_id_hotkey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.353063</td>\n",
       "      <td>0.351777</td>\n",
       "      <td>0.014625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.353063</td>\n",
       "      <td>0.351777</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.121350</td>\n",
       "      <td>0.121365</td>\n",
       "      <td>0.015996</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.121572</td>\n",
       "      <td>0.114903</td>\n",
       "      <td>0.008684</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.312157</td>\n",
       "      <td>0.314216</td>\n",
       "      <td>0.069470</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    avgFare  distance  avgDelay  airline_id_hotkey\n",
       "0  0.353063  0.351777  0.014625                0.0\n",
       "1  0.353063  0.351777  0.010969                0.0\n",
       "2  0.121350  0.121365  0.015996                0.0\n",
       "3  0.121572  0.114903  0.008684                0.0\n",
       "4  0.312157  0.314216  0.069470                0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.03538806783786465\n"
     ]
    }
   ],
   "source": [
    "# Calculate the root mean squared error (RMSE) as the evaluation metric\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          avgFare  distance  avgDelay  airline_id_hotkey\n",
      "0        0.353063  0.351777  0.014625           0.000000\n",
      "1        0.353063  0.351777  0.010969           0.000000\n",
      "2        0.121350  0.121365  0.015996           0.000000\n",
      "3        0.121572  0.114903  0.008684           0.000000\n",
      "4        0.312157  0.314216  0.069470           0.000000\n",
      "...           ...       ...       ...                ...\n",
      "1018941  0.104568  0.104806  0.007313           0.727273\n",
      "1018942  0.444370  0.455775  0.068556           0.727273\n",
      "1018943  0.172777  0.177302  0.013254           0.727273\n",
      "1018944  0.252342  0.240509  0.047075           0.727273\n",
      "1018945  0.033705  0.032310  0.105119           0.727273\n",
      "\n",
      "[1018946 rows x 4 columns]\n",
      "x training data          avgFare  distance  airline_id_hotkey\n",
      "337377  0.212805  0.171244           0.818182\n",
      "872780  0.059773  0.059774           0.818182\n",
      "575174  0.330161  0.341276           0.909091\n",
      "155242  0.276799  0.256260           0.818182\n",
      "58406   0.152228  0.147415           0.181818\n",
      "...          ...       ...                ...\n",
      "259178  0.510155  0.493538           0.181818\n",
      "365838  0.128892  0.125202           0.818182\n",
      "131932  0.207469  0.186389           0.909091\n",
      "671155  0.117627  0.110258           0.545455\n",
      "121958  0.429034  0.477989           1.000000\n",
      "\n",
      "[815156 rows x 3 columns]\n",
      "x val data           avgFare  distance  airline_id_hotkey\n",
      "9515     0.000000  0.023425           0.272727\n",
      "690108   0.280354  0.309168           0.090909\n",
      "1001323  0.444417  0.536753           0.090909\n",
      "242382   0.071069  0.072496           0.818182\n",
      "538114   0.227837  0.213853           0.818182\n",
      "...           ...       ...                ...\n",
      "358547   0.504172  0.502827           0.727273\n",
      "671965   0.017327  0.013934           0.454545\n",
      "925434   0.161474  0.142771           0.818182\n",
      "798738   0.202502  0.203150           0.818182\n",
      "502645   0.403862  0.393376           0.000000\n",
      "\n",
      "[203790 rows x 3 columns]\n",
      "y training data 337377    0.009598\n",
      "872780    0.014168\n",
      "575174    0.019196\n",
      "155242    0.018282\n",
      "58406     0.056216\n",
      "            ...   \n",
      "259178    0.010969\n",
      "365838    0.011883\n",
      "131932    0.039762\n",
      "671155    0.124314\n",
      "121958    0.024680\n",
      "Name: avgDelay, Length: 815156, dtype: float64\n",
      "y val data 9515       0.047075\n",
      "690108     0.013254\n",
      "1001323    0.007770\n",
      "242382     0.115631\n",
      "538114     0.022395\n",
      "             ...   \n",
      "358547     0.016910\n",
      "671965     0.019653\n",
      "925434     0.006399\n",
      "798738     0.039762\n",
      "502645     0.010512\n",
      "Name: avgDelay, Length: 203790, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Select the numeric columns that you want to normalize\n",
    "numeric_columns = ['avgFare', 'distance', 'avgDelay', 'airline_id_hotkey']\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Fit and transform the selected numeric columns\n",
    "test[numeric_columns] = scaler.fit_transform(traffic_processed[numeric_columns])\n",
    "\n",
    "print(test)\n",
    "\n",
    "X = test[['avgFare', 'distance', 'airline_id_hotkey']]\n",
    "y = test['avgDelay']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"x training data {X_train}\")\n",
    "print(f\"x val data {X_val}\")\n",
    "print(f\"y training data {y_train}\")\n",
    "print(f\"y val data {y_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['avgFare', 'distance', 'airline_id_hotkey'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 14\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Fit and transform the selected numeric columns\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# test[numeric_columns] = scaler.fit_transform(traffic_processed[numeric_columns])\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(test)\n\u001b[1;32m---> 14\u001b[0m X \u001b[39m=\u001b[39m test[[\u001b[39m'\u001b[39;49m\u001b[39mavgFare\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mdistance\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mairline_id_hotkey\u001b[39;49m\u001b[39m'\u001b[39;49m]]\n\u001b[0;32m     15\u001b[0m y \u001b[39m=\u001b[39m test[\u001b[39m'\u001b[39m\u001b[39mavgDelay\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39m# Split the data into training and validation sets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5938\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m     \u001b[39mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   5937\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[1;32m-> 5938\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m   5941\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['avgFare', 'distance', 'airline_id_hotkey'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Select the numeric columns that you want to normalize\n",
    "numeric_columns = ['avgFare', 'distance', 'avgDelay', 'airline_id_hotkey']\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "test = pd.DataFrame()\n",
    "\n",
    "# Fit and normalize the selected numeric columns\n",
    "test[numeric_columns] = scaler.fit_transform(traffic_processed[numeric_columns])\n",
    "\n",
    "print(test)\n",
    "\n",
    "X = test[['avgFare', 'distance', 'airline_id_hotkey']]\n",
    "y = test['avgDelay']\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train)\n",
    "print(X_val)\n",
    "print(y_train)\n",
    "print(y_val)\n",
    "\n",
    "# Train the XGBoost regression model\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate the root mean squared error (RMSE) as the evaluation metric\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Check if the data is approximately normally distributed\n",
    "# Using Shapiro-Wilk test (null hypothesis: data is normally distributed)\n",
    "_, p_value = stats.shapiro(y_pred)\n",
    "is_normal = p_value > 0.05\n",
    "\n",
    "print(is_normal)\n",
    "\n",
    "# If data is not normally distributed, try to find the best-fitting distribution\n",
    "if not is_normal:\n",
    "    # Candidate distributions to consider\n",
    "    candidate_distributions = [\n",
    "        stats.norm,        # Normal distribution\n",
    "        stats.expon,       # Exponential distribution\n",
    "        stats.gamma,       # Gamma distribution\n",
    "        stats.lognorm,     # Log-normal distribution\n",
    "        stats.weibull_min  # Weibull distribution (minimum)\n",
    "    ]\n",
    "    \n",
    "    # Fit different distributions and find the best one based on minimum AIC (Akaike Information Criterion)\n",
    "    best_distribution = None\n",
    "    best_params = ()\n",
    "    best_aic = float(\"inf\")\n",
    "    \n",
    "    for distribution in candidate_distributions:\n",
    "        params = distribution.fit(y_pred)\n",
    "        _, k = stats.kstest(y_pred, distribution(*params).cdf)\n",
    "        aic = len(y_pred) * np.log(k) + 2 * len(params)\n",
    "        if aic < best_aic:\n",
    "            best_distribution = distribution\n",
    "            best_params = params\n",
    "            best_aic = aic\n",
    "\n",
    "    # Generate the probability distribution using the best-fitting distribution\n",
    "    prob_distribution = best_distribution(*best_params).rvs(size=1000)\n",
    "else:\n",
    "    # If data is normally distributed, use the predicted values directly\n",
    "    prob_distribution = y_pred\n",
    "\n",
    "\n",
    "# Plot the probability distribution\n",
    "plt.hist(prob_distribution, bins=30, density=True, alpha=0.6, color='g')\n",
    "plt.xlabel('Average Delay Time')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Probability Distribution of Average Delay Time')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_avg_delay(airline_id, distance, avgFare):\n",
    "#     # Assuming 'df' is the DataFrame containing the dataset\n",
    "#     airline_id_hotkey = traffic_processed.loc[traffic_processed['airline_id'] == airline_id, 'airline_id_hotkey'].values[0]\n",
    "\n",
    "#     # Normalize the user inputs using the same scaler used for training data\n",
    "#     inputs = pd.DataFrame({'avgFare': [avgFare], 'distance': [distance], 'airline_id_hotkey': [airline_id_hotkey]})\n",
    "#     inputs_scaled = pd.DataFrame(scaler.transform(inputs), columns=inputs.columns)\n",
    "\n",
    "#     # Use the trained model to predict the average delay\n",
    "#     predicted_delay = model.predict(inputs_scaled[['avgFare', 'distance', \"airline_id_hotkey\"]])[0]\n",
    "\n",
    "#     # Check if the data is approximately normally distributed\n",
    "#     # Using Shapiro-Wilk test (null hypothesis: data is normally distributed)\n",
    "#     _, p_value = stats.shapiro(y_pred)\n",
    "#     is_normal = p_value > 0.05\n",
    "\n",
    "#     if not is_normal:\n",
    "#         # If data is not normally distributed, use the best-fitting distribution for probability calculation\n",
    "#         probability = np.mean(prob_distribution >= predicted_delay)\n",
    "#     else:\n",
    "#         # If data is normally distributed, use the predicted values directly\n",
    "#         probability = None  # Or any other appropriate value indicating that probability is not calculated\n",
    "\n",
    "#     return predicted_delay, probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_avg_delay(avgFare, distance, airline_id):\n",
    "    # Assuming 'df' is the DataFrame containing the dataset\n",
    "\n",
    "    # Find the airline_id_hotkey for the given airline_id\n",
    "    matching_rows = traffic_processed.loc[traffic_processed['airline_id'] == airline_id, 'airline_id_hotkey']\n",
    "    if matching_rows.any():\n",
    "        airline_id_hotkey = matching_rows.values[0]\n",
    "    else:\n",
    "        raise ValueError(f\"No matching airline_id found for: {airline_id}\")\n",
    "\n",
    "    # Prepare the input for prediction\n",
    "    input_data = pd.DataFrame({'airline_id_hotkey': [airline_id_hotkey], 'avgFare': [avgFare], 'distance': [distance]})\n",
    "\n",
    "    # Use the trained model to predict the average delay\n",
    "    predicted_delay = model.predict(input_data)[0]\n",
    "\n",
    "    # Check if the data is approximately normally distributed\n",
    "    # Using Shapiro-Wilk test (null hypothesis: data is normally distributed)\n",
    "    _, p_value = stats.shapiro(y_pred)\n",
    "    is_normal = p_value > 0.05\n",
    "\n",
    "    if not is_normal:\n",
    "        # If data is not normally distributed, use the best-fitting distribution for probability calculation\n",
    "        probability = np.mean(prob_distribution >= predicted_delay)\n",
    "    else:\n",
    "        # If data is normally distributed, use None as probability (not applicable)\n",
    "        probability = None\n",
    "\n",
    "    return predicted_delay, probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['avgFare', 'distance', 'airline_id_hotkey'] ['airline_id_hotkey', 'avgFare', 'distance']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m distance \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m      8\u001b[0m avgFare \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m\n\u001b[1;32m---> 10\u001b[0m predicted_delay, probability \u001b[39m=\u001b[39m predict_avg_delay(avgFare\u001b[39m=\u001b[39;49m avgFare, distance\u001b[39m=\u001b[39;49m distance, airline_id\u001b[39m=\u001b[39;49m airline_id)\n\u001b[0;32m     12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPredicted Average Delay: \u001b[39m\u001b[39m{\u001b[39;00mpredicted_delay\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[39mif\u001b[39;00m probability \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[61], line 15\u001b[0m, in \u001b[0;36mpredict_avg_delay\u001b[1;34m(avgFare, distance, airline_id)\u001b[0m\n\u001b[0;32m     12\u001b[0m input_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mairline_id_hotkey\u001b[39m\u001b[39m'\u001b[39m: [airline_id_hotkey], \u001b[39m'\u001b[39m\u001b[39mavgFare\u001b[39m\u001b[39m'\u001b[39m: [avgFare], \u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m: [distance]})\n\u001b[0;32m     14\u001b[0m \u001b[39m# Use the trained model to predict the average delay\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m predicted_delay \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(input_data)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m \u001b[39m# Check if the data is approximately normally distributed\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m# Using Shapiro-Wilk test (null hypothesis: data is normally distributed)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m _, p_value \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mshapiro(y_pred)\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\xgboost\\sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1113\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1114\u001b[0m         predts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_booster()\u001b[39m.\u001b[39;49minplace_predict(\n\u001b[0;32m   1115\u001b[0m             data\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m   1116\u001b[0m             iteration_range\u001b[39m=\u001b[39;49miteration_range,\n\u001b[0;32m   1117\u001b[0m             predict_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmargin\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m output_margin \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1118\u001b[0m             missing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmissing,\n\u001b[0;32m   1119\u001b[0m             base_margin\u001b[39m=\u001b[39;49mbase_margin,\n\u001b[0;32m   1120\u001b[0m             validate_features\u001b[39m=\u001b[39;49mvalidate_features,\n\u001b[0;32m   1121\u001b[0m         )\n\u001b[0;32m   1122\u001b[0m         \u001b[39mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1123\u001b[0m             \u001b[39mimport\u001b[39;00m \u001b[39mcupy\u001b[39;00m  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\xgboost\\core.py:2286\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2284\u001b[0m     data, fns, _ \u001b[39m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2285\u001b[0m     \u001b[39mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2286\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_features(fns)\n\u001b[0;32m   2288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[0;32m   2289\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m _ensure_np_dtype\n",
      "File \u001b[1;32mc:\\Users\\shiva\\OneDrive\\Documents\\GitHub\\Projects\\Work\\Citadel-Datathon\\venv\\Lib\\site-packages\\xgboost\\core.py:2782\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   2776\u001b[0m \u001b[39mif\u001b[39;00m my_missing:\n\u001b[0;32m   2777\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m   2778\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mtraining data did not have the following fields: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2779\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mstr\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m my_missing)\n\u001b[0;32m   2780\u001b[0m     )\n\u001b[1;32m-> 2782\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['avgFare', 'distance', 'airline_id_hotkey'] ['airline_id_hotkey', 'avgFare', 'distance']"
     ]
    }
   ],
   "source": [
    "# this is how the model was trained\n",
    "# Train the XGBoost regression model\n",
    "# model = xgb.XGBRegressor()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "airline_id = 'AA'\n",
    "distance = 1000\n",
    "avgFare = 300\n",
    "\n",
    "predicted_delay, probability = predict_avg_delay(avgFare= avgFare, distance= distance, airline_id= airline_id)\n",
    "\n",
    "print(f\"Predicted Average Delay: {predicted_delay}\")\n",
    "if probability is not None:\n",
    "    print(f\"Probability of Delay >= Predicted Delay: {probability}\")\n",
    "else:\n",
    "    print(\"Probability calculation is not available for normal distribution case.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
